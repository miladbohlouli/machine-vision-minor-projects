{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=False, precision=2)\n",
    "source_dir = \"images/\"\n",
    "save_dir = \"save/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reform_image(image):\n",
    "    image -= np.min(image)\n",
    "    image = image / np.max(image)\n",
    "    return (image * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cdf(image):\n",
    "    hist, bins = np.histogram(image.flatten(),256,[0,256])\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    plt.hist(image.flatten(), 256, [0, 256], color=\"red\")\n",
    "    plt.plot(cdf_normalized, color=\"b\")\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_read(path, blurring=False, histogram_euqalization = True):\n",
    "    image = cv2.imread(path, 0)\n",
    "\n",
    "    if histogram_euqalization:\n",
    "        hist, bins = np.histogram(image.flatten(),256,[0,256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_m = np.ma.masked_equal(cdf,0)\n",
    "        cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "        cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "        image = cdf[image]\n",
    "    \n",
    "    if blurring:\n",
    "        image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, title=None, save_name=None):\n",
    "    if len(image.shape) == 3:\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "        \n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title, size=9)\n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_dir + save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_subplot(images, suptitle, titles, column_numbers = 5, save = None):\n",
    "    plt.figure(figsize=[20, int(np.log(len(images)) * 5)+10])\n",
    "    num_images = len(images)\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(int(num_images / column_numbers) + 1, column_numbers, i + 1)\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.imshow(images[i], cmap=\"gray\")\n",
    "        plt.title(titles[i], size=10)\n",
    "        plt.suptitle(suptitle, size=20)\n",
    "        \n",
    "    if save is not None:\n",
    "        plt.savefig(save_dir + save)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to return the list of the kernels that have the given parameters\n",
    "# It returns the kernels of the given parameters\n",
    "\n",
    "def build_gabor_filters(ksize, sigmas, thetas, lambdas, gammas):\n",
    "    total_number_of_kernels = len(sigmas) * len(thetas) * len(lambdas) * len(gammas)\n",
    "    coloumn_nums = 5\n",
    "    counter = 1\n",
    "    kernels = []\n",
    "    kernel_types = []\n",
    "    for sigma in sigmas:\n",
    "        for theta in thetas:\n",
    "            for lambd in lambdas:\n",
    "                for gamma in gammas:\n",
    "                    kernel = cv2.getGaborKernel(ksize, sigma, theta, lambd, gamma, 0, ktype=cv2.CV_32F)\n",
    "                    kernels.append(kernel)\n",
    "                    kernel_type = \"s:%.1f & th:%.1f & l:%.1f & g:%.1f\"%(sigma, theta, lambd, gamma)\n",
    "                    kernel_types.append(kernel_type)\n",
    "                    counter += 1 \n",
    "                    \n",
    "    return kernels, kernel_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(source_dir, blurring=True, debug = True, histogram_euqalization=True):\n",
    "    image_lists_name = os.listdir(source_dir)\n",
    "    image_lists = []\n",
    "    image_shapes = []\n",
    "    dataset_dict = {\"Bricks\":[],\n",
    "               \"Gravel\":[],\n",
    "               \"Grass\":[]}\n",
    "    dataset_dict_resized = {\"Bricks\":[],\n",
    "                            \"Gravel\":[],\n",
    "                            \"Grass\":[]} \n",
    "\n",
    "    for image_name in image_lists_name:\n",
    "        image = image_read(source_dir + image_name, blurring, histogram_euqalization)\n",
    "        image_shapes.append(image.shape[:2])\n",
    "        if \"1\" in image_name:\n",
    "            dataset_dict[image_name.split(\"_\")[0]].insert(0, image)\n",
    "        else:\n",
    "            dataset_dict[image_name.split(\"_\")[0]].append(image)\n",
    "    \n",
    "    image_shapes = np.asarray(image_shapes)\n",
    "    image_x, image_y = np.mean(image_shapes, axis=0).astype(int)\n",
    "    resize = lambda image: cv2.convertScaleAbs(cv2.resize(image, (image_y, image_x), interpolation=cv2.INTER_AREA))\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Resizing the images into ({image_x}, {image_y})\")\n",
    "    \n",
    "    dataset = []\n",
    "    # Resizing the images\n",
    "    for key, image_group in dataset_dict.items():\n",
    "        dataset_dict[key] = list(map(resize, image_group))\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qualitative(images, true_labels, predicted_labels, num_columns = 4, save=None):\n",
    "    len_images = len(images)\n",
    "    num_raws = len_images // num_columns + 1\n",
    "    plt.figure(figsize=[20, len(images)])\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(num_raws, num_columns, i + 1)\n",
    "        show_image(image)\n",
    "        plt.title(f\"true:{true_labels[i]}  predicted:{predicted_labels[i]:d}\", size=14)\n",
    "        \n",
    "    if save is not None:\n",
    "        plt.savefig(save_dir+save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_dataset(source_dir, blurring=False, debug=False, histogram_euqalization=True)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(131)\n",
    "show_image(dataset[\"Bricks\"][0], \"Source image for bricks\")\n",
    "plt.subplot(132)\n",
    "show_image(dataset[\"Gravel\"][0], \"Source image for Gravel\")\n",
    "plt.subplot(133)\n",
    "show_image(dataset[\"Grass\"][0], \"Source image for Grass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just add values to the lists and thats it, the figure will be customized with the given values.\n",
    "\n",
    "ksize = (19, 19)  # must be a tuple\n",
    "sigma = [2]\n",
    "thetas = np.arange(0, np.pi, np.pi/4)\n",
    "lambdas = [0.5, 2]\n",
    "gammas = [0.6]\n",
    "\n",
    "sup_title = \"depicting the gabor kernels with diffrent parameters and kernel_size:\" + str(ksize) + \\\n",
    "                 \"\\ns: sigma, th: theta, l: lambda, g:gamma\"\n",
    "\n",
    "\n",
    "kernels, kernels_info = build_gabor_filters(ksize, sigma, thetas, lambdas, gammas)\n",
    "show_subplot(kernels, sup_title, kernels_info, save=\"gabor.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Gabor Kernels on the source images\n",
    "In the following cell the genrated gabor Kernels are applied to the source images and the result is saved in a numpy matrix with shape (image_x, image_y, number_of_kernels, number_of_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = dataset[\"Bricks\"][0].shape\n",
    "feature_mat = np.zeros((image_size[0], image_size[1], len(kernels), 3))\n",
    "\n",
    "num_kernels = len(kernels)\n",
    "plt.figure(figsize=(15, num_kernels*4))\n",
    "plt.subplot(num_kernels + 1, 4, 2)\n",
    "bricks_source = dataset[\"Bricks\"][0]\n",
    "show_image(bricks_source, \"Bricks\")\n",
    "plt.subplot(num_kernels + 1, 4, 3)\n",
    "gravel_source = dataset[\"Gravel\"][0]\n",
    "show_image(gravel_source, \"Gravel\")\n",
    "plt.subplot(num_kernels + 1, 4, 4)\n",
    "grass_source = dataset[\"Grass\"][0]\n",
    "show_image(grass_source, \"Grass\")\n",
    "\n",
    "for i in range(1, num_kernels + 1):\n",
    "    plt.subplot(num_kernels + 1, 4, i*4+1)\n",
    "    show_image(kernels[i-1], f\"{kernels_info[i-1]}\")\n",
    "    feature = cv2.filter2D(bricks_source, -1, kernels[i-1])\n",
    "    feature_mat[:, :, i - 1, 0] = feature\n",
    "    plt.subplot(num_kernels + 1, 4, i*4+2)\n",
    "    show_image(feature)\n",
    "    feature = cv2.filter2D(gravel_source, -1, kernels[i-1])\n",
    "    feature_mat[:, :, i - 1, 1] = feature\n",
    "    plt.subplot(num_kernels + 1, 4, i*4+3)\n",
    "    show_image(feature)\n",
    "    feature = cv2.filter2D(grass_source, -1, kernels[i-1])\n",
    "    feature_mat[:, :, i - 1, 2] = feature\n",
    "    plt.subplot(num_kernels + 1, 4, i*4+4)\n",
    "    show_image(feature)\n",
    "\n",
    "plt.savefig(save_dir+\"convolved_images.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The classification method\n",
    "In the below function the given test images will be classified according to the input features. \n",
    "The parameters of the function are as below:\n",
    "    1. feature_mat: explained previously, a matrix containing all of the features extracted from the source images.\n",
    "    2. test_images: a list containing the test images\n",
    "    3. kernels: All the Gabor kernels as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(feature_mat, test_images, kernels, debug=False):\n",
    "    labels = np.zeros((test_images.__len__()))\n",
    "    for i, image in enumerate(test_images):\n",
    "        print(f\"Classifying image ({i + 1:3d}/{len(test_images):3})\")\n",
    "        test_features = np.zeros((image.shape[0], image.shape[1], num_kernels))\n",
    "        for j, kernel in enumerate(kernels):\n",
    "            test_features[:, :, j] = cv2.filter2D(image, -1, kernels[j])\n",
    "\n",
    "#         value = np.mean(np.sum(np.sum(np.power(feature_mat - test_features[..., None], 2), axis=0), axis=0), axis=0)\n",
    "        \n",
    "    \n",
    "        #This is the mean and variance\n",
    "        features = [feature_mat.mean(axis=(0, 1)) - test_features[..., None].mean(axis=(0, 1)), \n",
    "                    np.var(feature_mat, axis=(0, 1)) - np.var(test_features[..., None], axis=(0, 1))]\n",
    "        features = np.asarray(features)\n",
    "        value = np.mean(np.sum(np.power(features, 2), axis=0), axis=0)\n",
    "        if debug:\n",
    "            print(value)\n",
    "        labels[i] = np.argmin(value, axis=-1)\n",
    "        \n",
    "    return labels.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [image for group_images in dataset.values() for i, image in enumerate(group_images) if i != 0]\n",
    "true_labels = np.asarray([0]*(len(test_images)//3) + [1]*(len(test_images)//3) + [2]*(len(test_images)//3), dtype=np.int)\n",
    "%time predicted_labels = classify(feature_mat, test_images, kernels, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitatitive and quantitive results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitive results\n",
    "print(\"#\"*20)\n",
    "print(\"The kernels were generated with the following conditions\")\n",
    "print(f\"kernel size: {ksize}\")\n",
    "print(f\"sigma: {sigma}\")\n",
    "print(f\"theta: {thetas}\")\n",
    "print(f\"lambda: {lambdas}\")\n",
    "print(f\"gamma: {gammas}\")\n",
    "print(f\"number of total kernels: {len(kernels)}\")\n",
    "\n",
    "print(\"\\n\"+\"#\"*20)\n",
    "print(\"The qualitative results are as below:\")\n",
    "precision = precision_score(true_labels, predicted_labels, average=\"micro\")\n",
    "f1 = f1_score(true_labels, predicted_labels, average=\"micro\")\n",
    "print(f\"The calculated precision:{precision:0.2f}\")\n",
    "print(f\"The calculated f1_score:{f1:0.2f}\")\n",
    "conf_mat = confusion_matrix(true_labels, predicted_labels)\n",
    "df = pd.DataFrame(conf_mat, index=[\"0\", \"1\", \"2\"], columns=[\"0\", \"1\", \"2\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative results\n",
    "qualitative(test_images, true_labels, predicted_labels, num_columns=4, save=\"classification_results.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
